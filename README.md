# ml_neural_networks

1. Описание задачи

Проект направлен на сравнение двух легковесных рекуррентных архитектур —
однослойной LSTM и GRU — для задачи классификации тональности текста на
примере датасета Sentiment140, доступного на Kaggle. Задача состоит в определении
положительной или негативной тональности твитов.

Критерии качества

• Accuracy (точность) — процент верно классифицированных твитов на
тестовой выборке.

• F1-score — метрика, учитывающая как точность, так и полноту модели.

3. Постановка задачи обучения
   
Датасет Sentiment140 содержит 1.6 миллиона твитов, размеченных по тональности:
положительные и негативные. Твиты были предварительно обработаны, чтобы
удалить шум и неинформативные символы.

Обучающее и тестовое множества

• Обучающее множество: 800 тыс. твитов.

• Тестовое множество: 200 тыс. твитов.

Алгоритм предобработки данных

• Токенизация и преобразование твитов в последовательности индексов.

Классификация данных

• Положительные: 500 тыс. твита

• Негативные: 500 тыс. твита


5. Описание используемых нейронных сетей
   
Архитектура сети

• LSTM: Однослойная сеть с 32 нейронами.

• GRU: Однослойная сеть с 32 нейронами.

Метод обучения и гиперпараметры

• Метод обучения: Adam

• Размер батчей: 1024

• Функция потерь: binary_crossentropy

• Число эпох: 10


7. Выводы по итогам вычислительного эксперимента
   
Анализ эффективности

• LSTM: Accuracy: 0.763, F1 Score: 0.773

• GRU: Accuracy: 0.764, F1 Score: 0.767

Сравнение

• Обе модели показали приблизительно одинаковые результаты.

